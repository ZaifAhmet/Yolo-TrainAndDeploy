{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " YOLO Model Eğitim ve Değerlendirme Akışı\n",
        "\n",
        "Bu notebook, özel bir veri kümesi üzerinde YOLO nesne algılama modeli eğitme, doğrulama ve sonuçları paketleme adımlarını içerir.\n",
        "\n",
        "**Adımlar:**\n",
        "1.  **GPU Kontrolü:** Çalışma ortamında GPU olup olmadığını kontrol eder.\n",
        "2.  **Veri Kümesi İndirme:** Roboflow'dan veri kümesini indirir.\n",
        "3.  **Veri Kümesi Çıkarma:** İndirilen zip dosyasını çıkarır.\n",
        "4.  **Veri Kümesi Yeniden Dengeleme ve Organizasyon:** Mevcut veri kümesini alır, resim ve etiketleri karıştırır ve belirtilen oranlara göre `train`, `valid`, `test` olarak yeniden böler. Yeni bir `data.yaml` dosyası oluşturur.\n",
        "5.  **Ultralytics Kurulumu:** YOLO11 ve ilgili araçları içeren `ultralytics` kütüphanesini kurar.\n",
        "6.  **YOLO Model Eğitimi:** Yeniden dengelenmiş veri kümesi ve belirtilen yapılandırma ile YOLO modelini eğitir. Eğitim sonrası en iyi model ile doğrulama yapar.\n",
        "7.  **Sonuçları Arşivleme:** Eğitim çıktılarını (en iyi model ağırlıkları, loglar, grafikler vb.) toplar ve bir zip dosyası olarak paketler."
      ],
      "metadata": {
        "id": "kRb4lquh_ZzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu hücre, Colab ortamında kullanılabilir bir NVIDIA GPU olup olmadığını kontrol etmek için nvidia-smi komutunu çalıştırır. Eğer bir GPU varsa, modeli, sürücü versiyonu ve bellek kullanımı gibi bilgileri listeler. Bu, model eğitimi gibi yoğun hesaplama gerektiren işlemler için önemlidir."
      ],
      "metadata": {
        "id": "iq0K4GrB_pdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. GPU Kontrolü\n",
        "# Bu komut, NVIDIA GPU'larının durumunu ve kullanılabilirliğini listeler.\n",
        "# Eğer bir GPU varsa, modeli ve sürücü versiyonunu, bellek kullanımını vb. gösterir.\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "cO957H5A_Oy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu hücre, Roboflow platformundan sağlanan bir URL aracılığıyla özel bir veri kümesini indirir.\n",
        "-O /content/data.zip: İndirilen dosyayı /content/ dizinine data.zip adıyla kaydeder.\n",
        "https://app.roboflow.com/ds/uOodPMnwHn?key=8u2eVuAw14: Veri kümesinin indirme bağlantısı. key parametresi, bu özel veri kümesine erişim için bir API anahtarı içerir."
      ],
      "metadata": {
        "id": "zAhXzSFk_qrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Veri Kümesi İndirme\n",
        "# Roboflow platformundan sağlanan URL aracılığıyla veri kümesini indirir.\n",
        "# '-O /content/data.zip' seçeneği, indirilen dosyayı '/content/data.zip' olarak kaydeder.\n",
        "# 'key' parametresi, özel veri kümesine erişim için bir API anahtarıdır.\n",
        "!wget -O /content/data.zip https://universe.roboflow.com/ds/nmGz9ajNlF?key=oGO5G6pgvq"
      ],
      "metadata": {
        "id": "I4bC4YVg_s4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu hücre, bir önceki adımda indirilen data.zip dosyasının içeriğini /content/custom_data adlı bir klasöre çıkarır.\n",
        "-q: \"Quiet\" modu, çıkarma işlemi sırasında detaylı dosya listesi çıktısını gizler, sadece hatalar gösterilir.\n",
        "-d /content/custom_data: Çıkarılan dosyaların kaydedileceği hedef dizini belirtir.\n"
      ],
      "metadata": {
        "id": "-OKIJjt2_v0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Veri Kümesi Çıkarma\n",
        "# İndirilen '/content/data.zip' dosyasını '/content/custom_data' klasörüne çıkarır.\n",
        "# '-q' (quiet) seçeneği, çıkarma işlemi sırasında detaylı çıktıları gizler.\n",
        "# '-d /content/custom_data' seçeneği, çıktı dosyalarının kaydedileceği dizini belirtir.\n",
        "!unzip -q /content/data.zip -d /content/custom_data"
      ],
      "metadata": {
        "id": "AIKZGsJR_veP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu uzun kod hücresi, indirilen ve çıkarılan veri kümesini YOLO eğitimi için uygun bir formata getirmek üzere birkaç önemli işlem yapar:\n",
        "1. **Ayarlar:** Giriş (INPUT_DATA_DIR), çıkış (OUTPUT_DATA_DIR) dizinleri ve veri kümesinin eğitim, doğrulama ve test setlerine bölünme oranları (TRAIN_RATIO, VALID_RATIO) tanımlanır.\n",
        "2. **Dosyaları Toplama:** Orijinal veri kümesindeki (/content/custom_data) train, valid, test klasörlerindeki tüm resim (.jpg, .png vb.) ve bunlara karşılık gelen etiket (.txt) dosyalarının yollarını toplar. Eşleşmeyen dosyalar için uyarı verir.\n",
        "3. **Karıştırma ve Bölme:** Toplanan resim-etiket çiftlerini rastgele karıştırır. Ardından, tanımlanan oranlara göre eğitim, doğrulama ve test setlerine ayırır.\n",
        "4. **Yeni Klasör Yapısı Oluşturma:** /content/rebalanced_data altında yeni train/images, train/labels, valid/images, valid/labels, test/images, test/labels klasörlerini oluşturur. Eğer bu klasörler zaten varsa, temizler.\n",
        "5. **Dosyaları Kopyalama:** Bölünen dosyaları yeni oluşturulan klasörlere kopyalar.\n",
        "6. **data.yaml Oluşturma:** YOLO eğitiminde kullanılacak olan data.yaml yapılandırma dosyasını oluşturur. Bu dosya, eğitim, doğrulama ve test setlerinin yollarını, sınıf sayısını (nc) ve sınıf isimlerini (names) içerir. Sınıf bilgilerini orijinal data.yaml dosyasından (varsa) almaya çalışır."
      ],
      "metadata": {
        "id": "zGV1qMVKATOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Veri Kümesi Yeniden Dengeleme ve Organizasyon\n",
        "# Bu betik, '/content/custom_data' içindeki mevcut veri kümesini (train, valid, test klasörlerinden)\n",
        "# alır, tüm resim ve etiketleri birleştirir, karıştırır ve ardından belirtilen oranlarda\n",
        "# '/content/rebalanced_data' altında yeni train, valid, test klasörlerine böler.\n",
        "# Ayrıca, yeni oluşturulan veri kümesi için bir 'data.yaml' dosyası da oluşturur.\n",
        "\n",
        "import os\n",
        "import shutil # Dosya ve klasör işlemleri için (kopyalama, silme vb.)\n",
        "import random # Dosyaları karıştırmak için\n",
        "from pathlib import Path # Modern dosya yolu işlemleri için\n",
        "import yaml # YAML dosyalarını okumak ve yazmak için (PyYAML kütüphanesi)\n",
        "\n",
        "# --- Ayarlar ---\n",
        "INPUT_DATA_DIR = Path(\"/content/custom_data\") # Orijinal veri kümesinin bulunduğu ana klasör\n",
        "OUTPUT_DATA_DIR = Path(\"/content/rebalanced_data\") # Yeniden dengelenmiş veri kümesinin kaydedileceği klasör\n",
        "TRAIN_RATIO = 0.8  # Eğitim seti için toplam veri kümesinin oranı (%80)\n",
        "VALID_RATIO = 0.11 # Doğrulama seti için toplam veri kümesinin oranı (%11)\n",
        "# TEST_RATIO, (1 - TRAIN_RATIO - VALID_RATIO) olarak otomatik hesaplanacak (%9)\n",
        "\n",
        "# --- 1. Tüm resim ve etiket dosyalarını topla ---\n",
        "all_image_paths = [] # Tüm resim dosyalarının yollarını tutacak liste\n",
        "all_label_paths = [] # Tüm etiket dosyalarının yollarını tutacak liste\n",
        "\n",
        "print(\"Mevcut veri setindeki dosyalar toplanıyor...\")\n",
        "# Orijinal veri kümesindeki 'train', 'valid', 'test' klasörlerini dolaş\n",
        "for split_folder_name in [\"train\", \"valid\", \"test\"]:\n",
        "    image_folder = INPUT_DATA_DIR / split_folder_name / \"images\"\n",
        "    label_folder = INPUT_DATA_DIR / split_folder_name / \"labels\"\n",
        "\n",
        "    # Klasörlerin var olup olmadığını kontrol et\n",
        "    if not image_folder.exists():\n",
        "        print(f\"Uyarı: {image_folder} bulunamadı, bu bölüm atlanıyor.\")\n",
        "        continue # Bu bölümü atla ve sonraki split_folder_name'e geç\n",
        "    if not label_folder.exists():\n",
        "        print(f\"Uyarı: {label_folder} bulunamadı, bu bölüm atlanıyor.\")\n",
        "        continue\n",
        "\n",
        "    # Resim klasöründeki tüm dosyaları al (uzantıya bakılmaksızın)\n",
        "    for img_file_path in image_folder.glob(\"*.*\"): # .jpg, .png, vb. tüm resim formatlarını alır\n",
        "        # İlgili etiket dosyasının adını oluştur (örneğin, image1.jpg -> image1.txt)\n",
        "        label_file_name = img_file_path.stem + \".txt\" # .stem dosya adını uzantısız verir\n",
        "        label_file_path = label_folder / label_file_name\n",
        "\n",
        "        # Etiket dosyasının var olup olmadığını kontrol et\n",
        "        if label_file_path.exists():\n",
        "            all_image_paths.append(img_file_path)\n",
        "            all_label_paths.append(label_file_path)\n",
        "        else:\n",
        "            print(f\"Uyarı: {img_file_path} için etiket dosyası ({label_file_path}) bulunamadı. Bu resim atlanıyor.\")\n",
        "\n",
        "# Toplanan dosya olup olmadığını kontrol et\n",
        "if not all_image_paths:\n",
        "    print(\"Hiç resim dosyası bulunamadı. Lütfen INPUT_DATA_DIR yolunu kontrol edin.\")\n",
        "    # exit() # Colab'da script'i durdurmak için daha iyi bir yol, bir hata yükseltmek olabilir\n",
        "    raise SystemExit(\"Veri toplama başarısız, resim bulunamadı.\")\n",
        "\n",
        "print(f\"Toplam {len(all_image_paths)} adet resim ve etiket çifti bulundu.\")\n",
        "\n",
        "# --- 2. Dosyaları eşleştir ve karıştır ---\n",
        "# Resim ve etiket yollarını (Path nesneleri olarak) çiftler halinde sakla\n",
        "file_pairs = list(zip(all_image_paths, all_label_paths))\n",
        "random.shuffle(file_pairs) # Listeyi yerinde (in-place) karıştırır, böylece rastgele bir dağılım elde edilir\n",
        "\n",
        "# --- 3. Veri setini oranlara göre böl ---\n",
        "total_files = len(file_pairs)\n",
        "train_count = int(total_files * TRAIN_RATIO) # Eğitim seti için dosya sayısı\n",
        "valid_count = int(total_files * VALID_RATIO) # Doğrulama seti için dosya sayısı\n",
        "test_count = total_files - train_count - valid_count # Kalanlar test seti için\n",
        "\n",
        "# Karıştırılmış listeden dilimleyerek setleri oluştur\n",
        "train_files = file_pairs[:train_count]\n",
        "valid_files = file_pairs[train_count : train_count + valid_count]\n",
        "test_files = file_pairs[train_count + valid_count :]\n",
        "\n",
        "print(f\"\\nYeni dağılım:\")\n",
        "print(f\"Train: {len(train_files)} dosya ({len(train_files)/total_files*100:.1f}%)\")\n",
        "print(f\"Valid: {len(valid_files)} dosya ({len(valid_files)/total_files*100:.1f}%)\")\n",
        "print(f\"Test:  {len(test_files)} dosya ({len(test_files)/total_files*100:.1f}%)\")\n",
        "\n",
        "# --- 4. Yeni klasör yapısını oluştur ve dosyaları kopyala ---\n",
        "# Eğer çıktı klasörü zaten varsa, içeriğini sil (temiz bir başlangıç için)\n",
        "if OUTPUT_DATA_DIR.exists():\n",
        "    print(f\"\\nUyarı: {OUTPUT_DATA_DIR} klasörü zaten mevcut. İçeriği silinecek.\")\n",
        "    shutil.rmtree(OUTPUT_DATA_DIR) # Klasörü ve içeriğini rekürsif olarak siler\n",
        "OUTPUT_DATA_DIR.mkdir(parents=True, exist_ok=True) # Ana klasörü ve gerekirse üst klasörleri oluşturur\n",
        "\n",
        "# Dosyaları ilgili train/valid/test klasörlerine kopyalamak için yardımcı fonksiyon\n",
        "def create_split_folders_and_copy(file_list, split_name):\n",
        "    img_output_folder = OUTPUT_DATA_DIR / split_name / \"images\"\n",
        "    lbl_output_folder = OUTPUT_DATA_DIR / split_name / \"labels\"\n",
        "\n",
        "    # Hedef klasörleri oluştur (images ve labels)\n",
        "    img_output_folder.mkdir(parents=True, exist_ok=True)\n",
        "    lbl_output_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(f\"\\n{split_name} dosyaları kopyalanıyor...\")\n",
        "    copied_count = 0\n",
        "    for img_path, lbl_path in file_list:\n",
        "        try:\n",
        "            # shutil.copy2, dosya verilerini ve mümkünse meta verilerini kopyalar\n",
        "            shutil.copy2(img_path, img_output_folder / img_path.name)\n",
        "            shutil.copy2(lbl_path, lbl_output_folder / lbl_path.name)\n",
        "            copied_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Hata: {img_path} veya {lbl_path} kopyalanamadı. {e}\")\n",
        "    print(f\"{split_name} için {copied_count} dosya çifti kopyalandı.\")\n",
        "\n",
        "# Fonksiyonu her bir set için çağır\n",
        "create_split_folders_and_copy(train_files, \"train\")\n",
        "create_split_folders_and_copy(valid_files, \"valid\")\n",
        "create_split_folders_and_copy(test_files, \"test\")\n",
        "\n",
        "# --- 5. Yeni data.yaml dosyasını oluştur ---\n",
        "# Orijinal veri kümesindeki 'data.yaml' dosyasını bulup sınıf bilgilerini (names, nc) almayı dene\n",
        "original_yaml_path = INPUT_DATA_DIR / \"data.yaml\"\n",
        "names = [] # Sınıf isimleri listesi\n",
        "nc = 0     # Sınıf sayısı (number of classes)\n",
        "\n",
        "if original_yaml_path.exists():\n",
        "    try:\n",
        "        with open(original_yaml_path, 'r', encoding='utf-8') as f: # encoding eklendi\n",
        "            data_yaml_content = yaml.safe_load(f)\n",
        "        names = data_yaml_content.get('names', []) # 'names' anahtarı varsa al, yoksa boş liste\n",
        "        nc = data_yaml_content.get('nc', len(names)) # 'nc' varsa al, yoksa 'names' listesinin uzunluğunu kullan\n",
        "\n",
        "        # Orijinal YAML'da bu anahtarların olup olmadığını kontrol et\n",
        "        if not names and 'names' not in data_yaml_content:\n",
        "            print(\"Uyarı: Orijinal data.yaml dosyasında 'names' anahtarı bulunamadı.\")\n",
        "        if nc == 0 and 'nc' not in data_yaml_content and not names:\n",
        "             print(\"Uyarı: Orijinal data.yaml dosyasında 'nc' anahtarı bulunamadı ve 'names' de boş.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Uyarı: Orijinal data.yaml ({original_yaml_path}) okunamadı. Hata: {e}\")\n",
        "        print(\"Yeni data.yaml dosyası için sınıf bilgileri manuel olarak girilmeli veya varsayılanlar kullanılacak.\")\n",
        "else:\n",
        "    print(f\"Uyarı: Orijinal data.yaml ({original_yaml_path}) bulunamadı.\")\n",
        "    print(\"Yeni data.yaml dosyası için sınıf bilgileri manuel olarak girilmeli veya varsayılanlar kullanılacak.\")\n",
        "\n",
        "# Sınıf bilgileri hala eksikse ek kontroller yap\n",
        "if not names: # Eğer names hala boşsa (okunamadı veya orijinalde yoktu)\n",
        "    print(\"Sınıf isimleri (names) alınamadı. Yeni data.yaml eksik olabilir. 'classes.txt' kontrol edilebilir.\")\n",
        "if nc == 0 and names: # nc okunamadı ama names listesi dolu (örneğin, eski yaml'da nc yoktu)\n",
        "    nc = len(names)\n",
        "    print(f\"Sınıf sayısı (nc), 'names' listesinden {nc} olarak ayarlandı.\")\n",
        "elif nc == 0 and not names: # Hem nc hem de names alınamadı\n",
        "    print(\"Kritik Uyarı: Sınıf sayısı (nc) ve sınıf isimleri (names) belirlenemedi. YOLO eğitimi başarısız olabilir.\")\n",
        "    print(\"Lütfen '/content/rebalanced_data/data.yaml' dosyasını manuel olarak düzenleyin.\")\n",
        "\n",
        "# Yeni data.yaml içeriğini oluştur\n",
        "new_data_yaml_content = {\n",
        "    'path': str(OUTPUT_DATA_DIR.resolve()), # Mutlak yol, YOLO için genellikle daha iyidir\n",
        "    'train': 'train/images', # 'path'e göre göreceli yol\n",
        "    'val': 'valid/images',   # YOLO genellikle 'val' kullanır, 'valid' de kabul edilebilir\n",
        "    'test': 'test/images',   # İsteğe bağlı, test seti için\n",
        "    'nc': nc,\n",
        "    'names': names\n",
        "}\n",
        "\n",
        "new_yaml_path = OUTPUT_DATA_DIR / \"data.yaml\"\n",
        "try:\n",
        "    with open(new_yaml_path, 'w', encoding='utf-8') as f: # encoding eklendi\n",
        "        # sort_keys=False: YAML'daki anahtar sırasını korur\n",
        "        # default_flow_style=None: Daha okunabilir blok stili YAML üretir\n",
        "        yaml.dump(new_data_yaml_content, f, sort_keys=False, default_flow_style=None, allow_unicode=True)\n",
        "    print(f\"\\nYeni data.yaml dosyası şuraya oluşturuldu: {new_yaml_path}\")\n",
        "    print(\"data.yaml içeriği:\")\n",
        "    print(yaml.dump(new_data_yaml_content, sort_keys=False, default_flow_style=None, allow_unicode=True))\n",
        "except Exception as e:\n",
        "    print(f\"Hata: Yeni data.yaml dosyası ({new_yaml_path}) oluşturulamadı. Hata: {e}\")\n",
        "\n",
        "\n",
        "print(\"\\nVeri kümesi yeniden dengeleme ve organizasyon işlemi tamamlandı!\")\n",
        "print(f\"Yeniden dengelenmiş veri seti '{OUTPUT_DATA_DIR}' klasörüne kaydedildi.\")"
      ],
      "metadata": {
        "id": "4V_N6ErTA22t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu hücre, YOLOv11 (ve önceki versiyonları) gibi nesne algılama modellerini eğitmek ve kullanmak için gerekli olan ultralytics kütüphanesini pip kullanarak kurar."
      ],
      "metadata": {
        "id": "FQ0eoynfA6uX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Ultralytics Kurulumu\n",
        "# Ultralytics, YOLOv5, YOLOv8 gibi modelleri ve eğitim araçlarını içeren bir Python kütüphanesidir.\n",
        "# '!pip install ultralytics' komutu ile en son sürümü PyPI'dan indirip kurar.\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "xavearRtA8z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu hücre, ultralytics kütüphanesini kullanarak YOLO modelini eğitir:\n",
        "1. **GPU Kontrolü:** Tekrar GPU kullanılabilirliğini kontrol eder ve eğitim için device değişkenini ayarlar.\n",
        "2. **Model Yükleme:** YOLO(model_name) ile bir YOLO modeli yükler. model_name (örneğin, yolov8n.pt) önceden eğitilmiş bir modelin adı olabilir. Ultralytics, bu model mevcut değilse genellikle indirir.\n",
        "3. **Veri Yolu Kontrolü:** Bir önceki adımda oluşturulan /content/rebalanced_data/data.yaml dosyasının varlığını kontrol eder.\n",
        "4. **Model Eğitimi (model.train):**\n",
        " 1. data: Eğitim için kullanılacak data.yaml dosyasının yolu.\n",
        " 2. epochs: Eğitim döngüsü sayısı.\n",
        " 3. batch: Her iterasyonda işlenecek resim sayısı. GPU belleğine göre ayarlanmalıdır.\n",
        " 4. imgsz: Modele verilecek resimlerin boyutu.\n",
        " 5. cache: Veri yüklemesini hızlandırmak için resimlerin diskte veya RAM'de önbelleğe alınmasını sağlar.\n",
        " 6. workers: Veri yükleme işlemleri için kullanılacak paralel işlemci sayısı.\n",
        " 7. project: Eğitim sonuçlarının (ağırlıklar, loglar, grafikler) kaydedileceği ana klasör.\n",
        " 8. name: Bu özel eğitim çalıştırması için alt klasör adı.\n",
        " 9. exist_ok: Aynı name ile bir klasör varsa üzerine yazmaya izin verir.\n",
        " 10. optimizer: Kullanılacak optimizasyon algoritması (auto, SGD, Adam vb.).\n",
        " 11. amp: Otomatik Karışık Hassasiyet (AMP) kullanımı. Eğitimi hızlandırabilir ve VRAM kullanımını azaltabilir.\n",
        " 12. device: Eğitim için kullanılacak cihaz (cuda:0 veya cpu).\n",
        "5. **Doğrulama (model_best.val):** Eğitim tamamlandıktan sonra, en iyi performansı gösteren model ağırlıkları (best.pt) yüklenir ve doğrulama seti üzerinde performansı (mAP gibi metrikler) değerlendirilir.\n",
        "6. **Hata Yönetimi:** Eğitim sırasında \"out of memory\" gibi hatalar oluşursa, kullanıcıya bilgi verir ve GPU durumunu gösterir."
      ],
      "metadata": {
        "id": "GA3PluLpBE_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. YOLO Model Eğitimi\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import subprocess # nvidia-smi gibi harici komutları çalıştırmak için\n",
        "from pathlib import Path # Dosya yolu işlemleri için\n",
        "\n",
        "# GPU kullanılabilirliğini kontrol et\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\") # İlk kullanılabilir GPU'yu seç\n",
        "    print(f\"GPU kullanılabilir: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU bulunamadı, CPU üzerinde çalışılacak.\")\n",
        "\n",
        "# 1. Modeli yükle\n",
        "# 'yolo11n.pt' (veya 'yolov8n.pt' gibi) önceden eğitilmiş bir model olabilir veya özel bir model adı olabilir.\n",
        "# Eğer bu dosya mevcut değilse veya bir YAML yapılandırma dosyası değilse, Ultralytics\n",
        "# genellikle bu isimde bir modeli (varsa) indirir veya sıfırdan oluşturur (eğer bir .yaml ise).\n",
        "model_name = 'yolov8n.pt' # Kullanıcı 'yolo11n.pt' yazmıştı, yaygın bir model olan 'yolov8n.pt' ile değiştirildi. İstenirse eski haline getirilebilir.\n",
        "try:\n",
        "    model = YOLO(model_name) # Modeli yükle veya başlat\n",
        "    print(f\"'{model_name}' modeli başarıyla yüklendi/başlatıldı.\")\n",
        "except Exception as e:\n",
        "    print(f\"Hata: '{model_name}' modeli yüklenemedi. {e}\")\n",
        "    print(\"Lütfen geçerli bir model adı (.pt dosyası), YAML yapılandırma dosyası (.yaml) veya resmi bir YOLO modeli adı (örn: yolov8n) sağladığınızdan emin olun.\")\n",
        "    raise SystemExit(\"Model yükleme başarısız.\")\n",
        "\n",
        "# Veri YAML dosyasının yolu (bir önceki adımda oluşturulan, yeniden dengelenmiş veri için)\n",
        "data_yaml_path = '/content/rebalanced_data/data.yaml'\n",
        "if not Path(data_yaml_path).exists():\n",
        "    print(f\"Kritik Hata: Veri yapılandırma dosyası bulunamadı: {data_yaml_path}\")\n",
        "    print(\"Lütfen bir önceki ('Veri Kümesi Yeniden Dengeleme') hücrenin başarıyla çalıştığından emin olun.\")\n",
        "    raise SystemExit(\"data.yaml bulunamadı.\")\n",
        "\n",
        "# 2. Modeli eğit\n",
        "try:\n",
        "    print(f\"Eğitim başlatılıyor... Veri dosyası: {data_yaml_path}\")\n",
        "    results = model.train(\n",
        "        data=data_yaml_path,  # Veri kümesi yapılandırma dosyasının yolu\n",
        "        epochs=30,            # Eğitim yapılacak epoch sayısı\n",
        "        batch=50,             # Batch boyutu (GPU belleğine göre ayarlanabilir)\n",
        "        imgsz=416,            # Giriş resimlerinin boyutu (örn: 640, 416)\n",
        "        cache='disk',         # Veri yüklemesini hızlandırmak için resimleri diskte önbelleğe al ('ram' veya False da olabilir)\n",
        "        workers=2,            # Veri yükleme için kullanılacak işçi (worker) sayısı (CPU çekirdek sayısına göre)\n",
        "        project='runs/detect',# Eğitim sonuçlarının kaydedileceği ana klasör\n",
        "        name='train_experiment_epoch30', # Bu eğitim çalıştırması için özel isim (klasör adı olacak)\n",
        "        exist_ok=True,        # Eğer 'name' ile aynı isimde bir klasör varsa üzerine yazmaya izin ver\n",
        "        optimizer='auto',     # Optimizasyon algoritması ('SGD', 'Adam', 'AdamW', 'auto')\n",
        "        amp=True,             # Otomatik Karışık Hassasiyet (Automatic Mixed Precision) - eğitimi hızlandırır ve VRAM kullanımını azaltır\n",
        "        device=device,        # Eğitim için kullanılacak cihaz (CPU veya GPU)\n",
        "    )\n",
        "    print(\"Eğitim tamamlandı!\")\n",
        "\n",
        "    # `results` objesi, eğitimin bittiği epoch'un modelini ve save_dir'i içerebilir,\n",
        "    # ancak en iyi model genellikle `model.trainer.best` ile veya save_dir içinden alınır.\n",
        "    save_dir = Path(model.trainer.save_dir if hasattr(model, 'trainer') and model.trainer else results.save_dir)\n",
        "    print(f\"Sonuçlar şuraya kaydedildi: {save_dir}\")\n",
        "\n",
        "    # Eğitim sonrası en iyi modeli kullanarak doğrulama (validation)\n",
        "    print(\"\\nEğitilmiş en iyi model ile doğrulama yapılıyor...\")\n",
        "\n",
        "    best_model_path_str = None\n",
        "    if hasattr(model, 'trainer') and model.trainer and hasattr(model.trainer, 'best') and model.trainer.best:\n",
        "        best_model_path_str = str(model.trainer.best) # Path objesine dönüştürmeden önce string olduğundan emin olalım\n",
        "\n",
        "    if best_model_path_str and Path(best_model_path_str).exists():\n",
        "        print(f\"En iyi model yükleniyor: {best_model_path_str}\")\n",
        "        model_best = YOLO(best_model_path_str) # En iyi .pt dosyasını yükle\n",
        "        metrics = model_best.val(data=data_yaml_path, split='val') # data.yaml'daki 'val' setini ve doğru yaml'ı kullanır\n",
        "        print(\"Doğrulama metrikleri (mAP50-95):\", metrics.box.map)\n",
        "        print(\"Doğrulama metrikleri (mAP50):\", metrics.box.map50)\n",
        "        print(\"Doğrulama metrikleri (mAP75):\", metrics.box.map75)\n",
        "    else:\n",
        "        # Alternatif olarak, save_dir içindeki weights/best.pt'yi arayabiliriz\n",
        "        best_model_path_alt = save_dir / 'weights' / 'best.pt'\n",
        "        if best_model_path_alt.exists():\n",
        "            print(f\"En iyi model (alternatif yol) yükleniyor: {best_model_path_alt}\")\n",
        "            model_best = YOLO(str(best_model_path_alt))\n",
        "            metrics = model_best.val(data=data_yaml_path, split='val') # data.yaml'daki 'val' setini ve doğru yaml'ı kullanır\n",
        "            print(\"Doğrulama metrikleri (mAP50-95):\", metrics.box.map)\n",
        "            print(\"Doğrulama metrikleri (mAP50):\", metrics.box.map50)\n",
        "            print(\"Doğrulama metrikleri (mAP75):\", metrics.box.map75)\n",
        "        else:\n",
        "            print(f\"Uyarı: En iyi model ne '{best_model_path_str}' ne de '{best_model_path_alt}' yolunda bulunamadı.\")\n",
        "            print(f\"Lütfen '{save_dir / 'weights' / 'best.pt'}' yolunu manuel kontrol edin.\")\n",
        "            print(\"Doğrulama adımı atlanıyor.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Eğitim veya doğrulama sırasında bir hata oluştu: {e}\")\n",
        "    if \"out of memory\" in str(e).lower() and torch.cuda.is_available():\n",
        "        print(\"CUDA Out of Memory hatası! Batch boyutunu ('batch') düşürmeyi veya resim boyutunu ('imgsz') küçültmeyi deneyin.\")\n",
        "    if torch.cuda.is_available(): # Hata durumunda GPU durumunu tekrar kontrol et\n",
        "        print(\"\\nGPU Durumu (Hata Sonrası):\")\n",
        "        try:\n",
        "            # nvidia-smi komutunu çalıştır ve çıktısını al\n",
        "            output = subprocess.check_output(['nvidia-smi'], universal_newlines=True)\n",
        "            print(output)\n",
        "        except Exception as smi_e:\n",
        "            print(f\"nvidia-smi çalıştırılamadı: {smi_e}\")\n",
        "    raise # Hatanın tekrar yükseltilmesi, Colab'ın hücreyi hatalı olarak işaretlemesini sağlar"
      ],
      "metadata": {
        "id": "_6xtsLWmB9-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Eğitilmiş Modelin Test Seti Üzerinde Değerlendirilmesi ve Sonuçların Kaydedilmesi\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import os\n",
        "import shutil # Çıktı klasörünü yönetmek için\n",
        "\n",
        "# --- Ayarlar ---\n",
        "# Bir önceki eğitim adımında (model.train) 'project' ve 'name' parametreleriyle eşleşmeli\n",
        "EXPERIMENT_PARENT_DIR = Path(\"/content/runs/detect\")\n",
        "EXPERIMENT_NAME = \"train_experiment_epoch30\" # Eğitimin 'name' parametresi\n",
        "\n",
        "# Test edilecek modelin yolu (eğitim sonrası en iyi model)\n",
        "# Bu yol, eğitim çıktılarındaki best.pt dosyasını işaret etmelidir.\n",
        "BEST_MODEL_PATH = EXPERIMENT_PARENT_DIR / EXPERIMENT_NAME / \"weights\" / \"best.pt\"\n",
        "\n",
        "# Yeniden dengelenmiş veri setinin YAML dosyası\n",
        "# Bu dosya, test seti yolunu ('test': 'test/images') içermelidir.\n",
        "DATA_YAML_PATH = Path(\"/content/rebalanced_data/data.yaml\")\n",
        "\n",
        "# Test sonuçlarının kaydedileceği proje ve isim\n",
        "# Bu, eğitimden farklı bir klasörde sonuçları saklamak için kullanışlıdır.\n",
        "TEST_PROJECT_DIR = Path(\"/content/runs/test\") # Ana test çıktı klasörü\n",
        "TEST_RUN_NAME = \"test_on_rebalanced_data\"    # Bu test çalıştırması için özel isim\n",
        "\n",
        "# Test için kullanılacak resim boyutu (eğitimdeki imgsz ile aynı veya uyumlu olmalı)\n",
        "TEST_IMG_SIZE = 416 # Eğitimde kullandığınız imgsz değeriyle aynı yapın\n",
        "\n",
        "# Test için batch boyutu\n",
        "TEST_BATCH_SIZE = 48 # GPU belleğinize göre ayarlayabilirsiniz\n",
        "\n",
        "# --- 1. Gerekli Yolların ve Modelin Varlığını Kontrol Et ---\n",
        "if not BEST_MODEL_PATH.exists():\n",
        "    print(f\"HATA: En iyi model dosyası bulunamadı: {BEST_MODEL_PATH}\")\n",
        "    print(\"Lütfen bir önceki eğitim hücresinin başarıyla tamamlandığından ve 'best.pt' dosyasının oluştuğundan emin olun.\")\n",
        "    # Colab'da script'i durdurmak için:\n",
        "    raise SystemExit(\"Test edilecek model bulunamadı.\")\n",
        "\n",
        "if not DATA_YAML_PATH.exists():\n",
        "    print(f\"HATA: Veri YAML dosyası bulunamadı: {DATA_YAML_PATH}\")\n",
        "    print(\"Lütfen veri kümesi hazırlama adımlarının doğru tamamlandığından emin olun.\")\n",
        "    raise SystemExit(\"data.yaml bulunamadı.\")\n",
        "\n",
        "# --- 2. Test Çıktı Klasörünü Hazırla (İsteğe Bağlı ama Önerilir) ---\n",
        "# Eğer daha önce aynı isimle bir test çalıştırıldıysa, eski sonuçların üzerine yazılmasını önlemek\n",
        "# veya temiz bir başlangıç yapmak için eski klasörü silebiliriz.\n",
        "# Veya `exist_ok=True` parametresini .val() veya .predict() içinde kullanabiliriz.\n",
        "# Bu örnekte, YOLO'nun kendi 'exist_ok' mekanizmasına güveneceğiz.\n",
        "\n",
        "# --- 3. Modeli Yükle ---\n",
        "print(f\"Test için model yükleniyor: {BEST_MODEL_PATH}\")\n",
        "try:\n",
        "    model = YOLO(str(BEST_MODEL_PATH))\n",
        "    print(\"Model başarıyla yüklendi.\")\n",
        "except Exception as e:\n",
        "    print(f\"HATA: Model yüklenirken bir sorun oluştu: {e}\")\n",
        "    raise SystemExit(\"Model yükleme başarısız.\")\n",
        "\n",
        "# --- 4. Modeli Test Seti Üzerinde Değerlendir (metrics.val()) ---\n",
        "# .val() metodu, data.yaml dosyasında belirtilen 'test' (veya 'val') bölümünü kullanarak\n",
        "# mAP gibi standart metrikleri hesaplar.\n",
        "# Eğer data.yaml dosyanızda 'test' anahtarı doğru bir şekilde test verilerinizi gösteriyorsa,\n",
        "# split='test' parametresini kullanabilirsiniz. Eğer 'test' anahtarı yoksa veya\n",
        "# doğrulama (validation) setini test amacıyla kullanmak istiyorsanız split='val' kullanın.\n",
        "# data.yaml dosyamızda 'test' yolunun '/content/rebalanced_data/test/images' olduğunu varsayıyoruz.\n",
        "\n",
        "print(f\"\\nModel test seti üzerinde değerlendiriliyor (metrics.val())...\")\n",
        "print(f\"Veri YAML: {DATA_YAML_PATH}\")\n",
        "print(f\"Çıktılar şuraya kaydedilecek: {TEST_PROJECT_DIR / TEST_RUN_NAME}\")\n",
        "\n",
        "try:\n",
        "    metrics = model.val(\n",
        "        data=str(DATA_YAML_PATH),\n",
        "        split='test',  # data.yaml içindeki 'test' anahtarını kullanır\n",
        "        imgsz=TEST_IMG_SIZE,\n",
        "        batch=TEST_BATCH_SIZE,\n",
        "        project=str(TEST_PROJECT_DIR), # Sonuçların kaydedileceği ana klasör\n",
        "        name=TEST_RUN_NAME,         # Bu test çalıştırması için özel alt klasör adı\n",
        "        exist_ok=True,              # Eğer aynı isimde klasör varsa üzerine yaz\n",
        "        save_json=True,             # COCO formatında JSON sonuçları kaydeder (mAP hesaplaması için)\n",
        "        save_hybrid=True,           # Hem etiketleri hem de tahminleri içeren resimleri kaydeder (görsel inceleme için)\n",
        "        conf=0.25,                  # Tahminler için minimum güven eşiği (varsayılan)\n",
        "        iou=0.45                    # NMS için IoU eşiği (varsayılan)\n",
        "    )\n",
        "    print(\"\\nTest Değerlendirme Metrikleri:\")\n",
        "    if hasattr(metrics, 'box'):\n",
        "        print(f\"  mAP50-95: {metrics.box.map:.4f}\")\n",
        "        print(f\"  mAP50:    {metrics.box.map50:.4f}\")\n",
        "        print(f\"  mAP75:    {metrics.box.map75:.4f}\")\n",
        "        # Sınıf bazlı mAP değerlerini de yazdırabiliriz (eğer varsa)\n",
        "        if hasattr(metrics.box, 'maps') and metrics.box.maps is not None:\n",
        "            for i, class_name in enumerate(model.names):\n",
        "                 if i < len(metrics.box.maps): # maps dizisinin sınırları içinde mi kontrolü\n",
        "                    print(f\"  mAP50-95 ({class_name}): {metrics.box.maps[i]:.4f}\")\n",
        "    else:\n",
        "        print(\"Detaylı kutu metrikleri bulunamadı. Lütfen 'metrics' objesini kontrol edin.\")\n",
        "\n",
        "    print(f\"\\nDeğerlendirme sonuçları ve görseller şuraya kaydedildi: {TEST_PROJECT_DIR / TEST_RUN_NAME}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"HATA: Model değerlendirme (model.val()) sırasında bir sorun oluştu: {e}\")\n",
        "    raise\n",
        "\n",
        "# --- 5. Test Seti Üzerinde Tahminler Yap ve Sonuçları Kaydet (model.predict()) ---\n",
        "# model.predict() metodu, test setindeki her resim için tahminler yapar ve\n",
        "# bu tahminleri (sınırlayıcı kutular, etiketler, güven skorları ile birlikte) resimlerin üzerine çizebilir.\n",
        "\n",
        "print(f\"\\nTest seti üzerinde tahminler yapılıyor (model.predict())...\")\n",
        "# Tahminlerin kaydedileceği klasör, .val() ile aynı yapıda olacak şekilde ayarlanır.\n",
        "# YOLO, project/name yapısını kendi yönetir. predict() metodu içinde de benzer parametreler vardır.\n",
        "# Ancak, predict() doğrudan metrik hesaplamaz, daha çok görsel çıktı ve ham tahminler üretir.\n",
        "\n",
        "# Çıktıların kaydedileceği spesifik bir alt klasör belirleyelim\n",
        "PREDICT_SAVE_DIR = TEST_PROJECT_DIR / TEST_RUN_NAME / \"predictions\"\n",
        "PREDICT_SAVE_DIR.mkdir(parents=True, exist_ok=True) # Klasörü oluştur\n",
        "\n",
        "# data.yaml dosyasından test resimlerinin yolunu alalım\n",
        "import yaml\n",
        "with open(DATA_YAML_PATH, 'r') as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "# data.yaml'daki 'path' ve 'test' anahtarlarını birleştirerek tam yolu oluştur\n",
        "# Path(data_config['path']) mutlak bir yol olmalı (önceki hücrede öyle ayarlandı)\n",
        "test_images_path_pattern = Path(data_config['path']) / data_config['test']\n",
        "\n",
        "if not test_images_path_pattern.exists():\n",
        "     # Eğer path göreceli ise ve data.yaml ile aynı dizindeyse:\n",
        "     alternative_test_path = DATA_YAML_PATH.parent / data_config['test']\n",
        "     if alternative_test_path.exists():\n",
        "         test_images_path_pattern = alternative_test_path\n",
        "     else:\n",
        "        print(f\"HATA: Test resimleri yolu bulunamadı: {test_images_path_pattern} veya {alternative_test_path}\")\n",
        "        raise SystemExit(\"Test resim yolu hatalı.\")\n",
        "\n",
        "\n",
        "print(f\"Tahmin yapılacak resimler: {test_images_path_pattern}\")\n",
        "\n",
        "try:\n",
        "    results = model.predict(\n",
        "        source=str(test_images_path_pattern), # Test resimlerinin bulunduğu klasör veya glob deseni\n",
        "        imgsz=TEST_IMG_SIZE,\n",
        "        conf=0.25,        # Tahminler için minimum güven skoru\n",
        "        iou=0.45,         # NMS için IoU eşiği\n",
        "        save=True,        # Tahminlerin çizildiği resimleri kaydeder\n",
        "        save_txt=True,    # Tahminleri YOLO formatında .txt dosyalarına kaydeder\n",
        "        save_conf=True,   # .txt dosyalarına güven skorlarını da ekler\n",
        "        project=str(TEST_PROJECT_DIR), # Ana çıktı klasörü\n",
        "        name=TEST_RUN_NAME + \"_preds\", # Tahminler için ayrı bir alt klasör adı\n",
        "        exist_ok=True,\n",
        "        # line_width veya line_thickness gibi çizim parametreleri de eklenebilir\n",
        "    )\n",
        "    # results bir jeneratördür, her bir resim için sonuçları işleyebilirsiniz.\n",
        "    # Bu döngü, tahminlerin yapılmasını tetikler ve sonuçların kaydedilmesini sağlar.\n",
        "    processed_count = 0\n",
        "    for r in results:\n",
        "        processed_count +=1\n",
        "        # r.path, r.names, r.boxes vb. özelliklere erişebilirsiniz.\n",
        "        # Kaydetme işlemi yukarıdaki 'save=True' ile zaten yapılıyor.\n",
        "        pass # Sadece jeneratörü tüketmek için\n",
        "\n",
        "    print(f\"\\n{processed_count} resim için tahmin yapıldı ve sonuçlar kaydedildi.\")\n",
        "    print(f\"Tahmin görselleri ve .txt dosyaları şuraya kaydedildi: {TEST_PROJECT_DIR / (TEST_RUN_NAME + '_preds')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"HATA: Model tahmini (model.predict()) sırasında bir sorun oluştu: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"\\nTest ve tahmin işlemleri tamamlandı!\")"
      ],
      "metadata": {
        "id": "qvg8ewd95hFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu hücre, bir önceki eğitim adımında oluşturulan tüm önemli çıktıları (en iyi model ağırlıkları, eğitim logları, grafikler vb.) toplar ve tek bir .zip dosyası olarak paketler.\n",
        "1. **Ayarlar:** EXPERIMENT_NAME (bir önceki hücredeki model.train fonksiyonundaki name parametresiyle aynı olmalıdır), kaynak ve hedef dizinler, oluşturulacak geçici klasör adı ve son zip dosyasının adı tanımlanır.\n",
        "2. **Kaynak Kontrolü:** SOURCE_RUN_DIR (yani /content/runs/detect/train_experiment_epoch30) klasörünün var olup olmadığını kontrol eder.\n",
        "3. **Hedef Klasör Hazırlığı:** /content/my_yolo_model_outputs gibi geçici bir klasör oluşturur (varsa silip yeniden oluşturur).\n",
        "4. **En İyi Modelin Kopyalanması:** SOURCE_RUN_DIR/weights/best.pt dosyasını, hedef klasöre best_trained_model.pt adıyla kopyalar.\n",
        "5. **Tüm Çalıştırma Klasörünün Kopyalanması:** Tüm SOURCE_RUN_DIR (örneğin, train_experiment_epoch30) klasörünü, tüm içeriğiyle (loglar, grafikler vb.) hedef klasörün içine kopyalar.\n",
        "6. **Sıkıştırma:** Hedef klasörü (my_yolo_model_outputs) bir zip dosyası (my_trained_yolo_model_archive.zip) olarak /content dizinine sıkıştırır."
      ],
      "metadata": {
        "id": "vXkYIKYxCHeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Sonuçları Arşivleme (Genişletilmiş Kapsam)\n",
        "# Bu betik, eğitim çıktılarını, test çıktılarını ve potansiyel bir doğrulama çalıştırmasını\n",
        "# toplayıp tek bir zip dosyası olarak paketler.\n",
        "\n",
        "import os\n",
        "import shutil # Dosya ve klasör işlemleri için\n",
        "from pathlib import Path # Modern dosya yolu işlemleri için\n",
        "\n",
        "# --- Ayarlarınızı Buradan Yapılandırın ---\n",
        "# Eğitim betiğinizde model.train() içindeki 'name' parametresiyle aynı olmalı\n",
        "TRAIN_EXPERIMENT_NAME = \"train_experiment_epoch30\" # Eğitimin 'name' parametresi\n",
        "\n",
        "# Test çalıştırmasının adı (bir önceki test hücresindeki TEST_RUN_NAME ile aynı olmalı)\n",
        "TEST_RUN_NAME_VAL_METRICS = \"test_on_rebalanced_data\" # model.val() için kullanılan name\n",
        "TEST_RUN_NAME_PREDICTIONS = \"test_on_rebalanced_data_preds\" # model.predict() için kullanılan name\n",
        "\n",
        "# Potansiyel ayrı bir doğrulama çalıştırmasının adı (varsa)\n",
        "# Eğer eğitim sırasında otomatik doğrulama yapılıyorsa bu boş bırakılabilir veya None yapılabilir.\n",
        "# Eğer model.val() komutunu ayrı bir 'name' ile (örn: 'val') çalıştırdıysanız buraya onu yazın.\n",
        "SEPARATE_VAL_RUN_NAME = \"val\" # Örnek bir isim, eğer yoksa None yapın veya boş bırakın.\n",
        "\n",
        "# Kaynak dizinler\n",
        "SOURCE_DETECT_PARENT_DIR = Path(\"/content/runs/detect\") # Eğitim ve potansiyel doğrulama çıktıları\n",
        "SOURCE_TEST_PARENT_DIR = Path(\"/content/runs/test\")    # Test çıktıları\n",
        "\n",
        "# Hedef arşiv ayarları\n",
        "TARGET_ARCHIVE_PARENT_DIR = Path(\"/content\")\n",
        "TARGET_OUTPUT_FOLDER_NAME = \"my_complete_yolo_run_outputs\" # Zip açıldığında görünecek ana klasör adı\n",
        "ZIP_FILE_BASENAME = \"my_complete_yolo_archive\" # Oluşturulacak zip dosyasının adı\n",
        "\n",
        "# --- Yol Tanımlamaları ---\n",
        "SOURCE_TRAIN_RUN_DIR = SOURCE_DETECT_PARENT_DIR / TRAIN_EXPERIMENT_NAME\n",
        "SOURCE_TEST_VAL_METRICS_DIR = SOURCE_TEST_PARENT_DIR / TEST_RUN_NAME_VAL_METRICS\n",
        "SOURCE_TEST_PREDICTIONS_DIR = SOURCE_TEST_PARENT_DIR / TEST_RUN_NAME_PREDICTIONS\n",
        "\n",
        "SOURCE_SEPARATE_VAL_DIR = None\n",
        "if SEPARATE_VAL_RUN_NAME: # Eğer bir isim verilmişse\n",
        "    SOURCE_SEPARATE_VAL_DIR = SOURCE_DETECT_PARENT_DIR / SEPARATE_VAL_RUN_NAME\n",
        "\n",
        "TARGET_OUTPUT_DIR = TARGET_ARCHIVE_PARENT_DIR / TARGET_OUTPUT_FOLDER_NAME\n",
        "FINAL_ZIP_PATH = TARGET_ARCHIVE_PARENT_DIR / f\"{ZIP_FILE_BASENAME}.zip\"\n",
        "\n",
        "def copy_directory_if_exists(src_dir_path, dest_parent_path, new_folder_name=None):\n",
        "    \"\"\"\n",
        "    Kaynak dizini var ise hedefteki bir üst dizinin içine kopyalar.\n",
        "    Eğer new_folder_name verilirse, kaynak dizin bu isimle kopyalanır.\n",
        "    \"\"\"\n",
        "    if src_dir_path and src_dir_path.is_dir():\n",
        "        target_name = new_folder_name if new_folder_name else src_dir_path.name\n",
        "        dest_path = dest_parent_path / target_name\n",
        "        print(f\"'{src_dir_path.name}' klasörü kopyalanıyor:\")\n",
        "        print(f\"  Kaynak: {src_dir_path}\")\n",
        "        print(f\"  Hedef:  {dest_path}\")\n",
        "        try:\n",
        "            shutil.copytree(src_dir_path, dest_path)\n",
        "            print(f\"'{src_dir_path.name}' başarıyla kopyalandı.\\n\")\n",
        "            return True\n",
        "        except FileExistsError:\n",
        "            print(f\"Hata: Hedef klasör '{dest_path}' zaten mevcut. Bu bir sorun olmamalıydı.\")\n",
        "            return False # Veya üzerine yazma stratejisi eklenebilir\n",
        "        except Exception as e:\n",
        "            print(f\"Hata: '{src_dir_path.name}' kopyalanamadı. {e}\\n\")\n",
        "            return False\n",
        "    else:\n",
        "        if src_dir_path: # Yol tanımlı ama klasör değilse\n",
        "            print(f\"UYARI: Kaynak '{src_dir_path}' bulunamadı veya bir klasör değil. Kopyalama atlanıyor.\\n\")\n",
        "        # src_dir_path None ise (örn: SEPARATE_VAL_RUN_NAME verilmemişse) sessiz kal\n",
        "        return False\n",
        "\n",
        "\n",
        "def collect_and_zip_all_outputs():\n",
        "    print(\"Tüm model çıktılarını toplama ve sıkıştırma işlemi başlatılıyor...\\n\")\n",
        "\n",
        "    # 1. Hedef çıktı klasörünü oluştur (varsa üzerine yazılacak şekilde temizle)\n",
        "    print(f\"Hedef çıktı klasörü hazırlanıyor: {TARGET_OUTPUT_DIR}\")\n",
        "    if TARGET_OUTPUT_DIR.exists():\n",
        "        print(f\"Mevcut '{TARGET_OUTPUT_DIR}' klasörü siliniyor.\")\n",
        "        shutil.rmtree(TARGET_OUTPUT_DIR)\n",
        "    TARGET_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"'{TARGET_OUTPUT_DIR}' klasörü oluşturuldu/temizlendi.\\n\")\n",
        "\n",
        "    # 2. Eğitim çalıştırması klasörünü kopyala\n",
        "    if not SOURCE_TRAIN_RUN_DIR.is_dir():\n",
        "        print(f\"KRİTİK HATA: Ana eğitim çalıştırma dizini '{SOURCE_TRAIN_RUN_DIR}' bulunamadı!\")\n",
        "        print(\"Arşivleme işlemi devam edemez. Lütfen TRAIN_EXPERIMENT_NAME ayarını kontrol edin.\")\n",
        "        return\n",
        "    copy_directory_if_exists(SOURCE_TRAIN_RUN_DIR, TARGET_OUTPUT_DIR)\n",
        "\n",
        "    # 3. Test metrikleri çalıştırması klasörünü (/content/runs/test/test_on_rebalanced_data) kopyala\n",
        "    # Bu klasörü, ana çıktı klasörünün içine 'test_evaluation_metrics' gibi bir isimle kopyalayalım\n",
        "    copy_directory_if_exists(SOURCE_TEST_VAL_METRICS_DIR, TARGET_OUTPUT_DIR, new_folder_name=\"test_evaluation_metrics\")\n",
        "\n",
        "    # 4. Test tahminleri çalıştırması klasörünü (/content/runs/test/test_on_rebalanced_data_preds) kopyala\n",
        "    # Bu klasörü, ana çıktı klasörünün içine 'test_predictions_output' gibi bir isimle kopyalayalım\n",
        "    copy_directory_if_exists(SOURCE_TEST_PREDICTIONS_DIR, TARGET_OUTPUT_DIR, new_folder_name=\"test_predictions_output\")\n",
        "\n",
        "    # 5. Potansiyel ayrı doğrulama çalıştırması klasörünü (/content/runs/detect/val gibi) kopyala\n",
        "    if SOURCE_SEPARATE_VAL_DIR: # Sadece bir isim tanımlanmışsa ve klasör varsa kopyala\n",
        "        copy_directory_if_exists(SOURCE_SEPARATE_VAL_DIR, TARGET_OUTPUT_DIR, new_folder_name=\"separate_validation_run\")\n",
        "\n",
        "    # 6. (İsteğe Bağlı) En iyi model ağırlığını ana çıktı klasörünün köküne de kopyalayabiliriz\n",
        "    source_best_pt_path = SOURCE_TRAIN_RUN_DIR / \"weights\" / \"best.pt\"\n",
        "    target_best_pt_main_path = TARGET_OUTPUT_DIR / \"best_trained_model.pt\"\n",
        "    if source_best_pt_path.is_file():\n",
        "        print(f\"En iyi model ağırlıkları ayrıca ana çıktı klasörünün köküne kopyalanıyor:\")\n",
        "        print(f\"  Kaynak: {source_best_pt_path}\")\n",
        "        print(f\"  Hedef:  {target_best_pt_main_path}\")\n",
        "        shutil.copy(source_best_pt_path, target_best_pt_main_path)\n",
        "        print(\"Model ağırlıkları (kök kopya) başarıyla kopyalandı.\\n\")\n",
        "    else:\n",
        "        # Bu uyarı zaten eğitim klasörü kopyalanırken de verileceği için tekrar gerekmeyebilir,\n",
        "        # ancak burada da bulunması zararsızdır.\n",
        "        print(f\"UYARI: En iyi model ağırlık dosyası ({source_best_pt_path}) ana eğitim klasöründe bulunamadı.\\n\")\n",
        "\n",
        "\n",
        "    # 7. Hazırlanan hedef çıktı klasörünü sıkıştır\n",
        "    print(f\"Çıktılar sıkıştırılıyor...\")\n",
        "    print(f\"  Sıkıştırılacak klasör (base_dir): '{TARGET_OUTPUT_FOLDER_NAME}' (içeriği: {TARGET_OUTPUT_DIR})\")\n",
        "    print(f\"  Sıkıştırma kök dizini (root_dir): '{TARGET_ARCHIVE_PARENT_DIR}'\")\n",
        "    print(f\"  Oluşturulacak zip dosyası: {FINAL_ZIP_PATH}\")\n",
        "\n",
        "    try:\n",
        "        if FINAL_ZIP_PATH.exists():\n",
        "            print(f\"Mevcut zip dosyası siliniyor: {FINAL_ZIP_PATH}\")\n",
        "            FINAL_ZIP_PATH.unlink()\n",
        "\n",
        "        shutil.make_archive(\n",
        "            base_name=str(TARGET_ARCHIVE_PARENT_DIR / ZIP_FILE_BASENAME),\n",
        "            format='zip',\n",
        "            root_dir=str(TARGET_ARCHIVE_PARENT_DIR),\n",
        "            base_dir=TARGET_OUTPUT_FOLDER_NAME\n",
        "        )\n",
        "        print(f\"Sıkıştırma tamamlandı. Arşiv dosyası oluşturuldu: {FINAL_ZIP_PATH}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Sıkıştırma sırasında bir hata oluştu: {e}\\n\")\n",
        "        return\n",
        "\n",
        "    print(\"İşlem başarıyla tamamlandı!\")\n",
        "    print(f\"Tüm sonuçlar '{FINAL_ZIP_PATH}' dosyasına kaydedildi.\")\n",
        "    print(f\"Bu zip dosyasını Colab'ın sol tarafındaki dosya gezgininden indirebilirsiniz.\")\n",
        "    print(f\"Zip dosyasını açtığınızda içinde '{TARGET_OUTPUT_FOLDER_NAME}' adlı bir klasör bulacaksınız.\")\n",
        "    print(f\"Bu klasörün içinde (eğer kaynakları bulunduysa):\\n\"\n",
        "          f\"  - '{TRAIN_EXPERIMENT_NAME}/' (ana eğitim çıktıları)\\n\"\n",
        "          f\"  - 'test_evaluation_metrics/' (test seti değerlendirme metrikleri ve ilgili dosyalar)\\n\"\n",
        "          f\"  - 'test_predictions_output/' (test seti tahmin görselleri ve .txt dosyaları)\\n\"\n",
        "          f\"  - 'best_trained_model.pt' (eğitilmiş en iyi modelin bir kopyası)\\n\"\n",
        "          + (f\"  - 'separate_validation_run/' (ayrı bir doğrulama çalıştırması varsa onun çıktıları)\\n\" if SOURCE_SEPARATE_VAL_DIR and SOURCE_SEPARATE_VAL_DIR.is_dir() else \"\")\n",
        "         )\n",
        "\n",
        "# Betiği çalıştırmak için:\n",
        "if __name__ == \"__main__\":\n",
        "    collect_and_zip_all_outputs()"
      ],
      "metadata": {
        "id": "UOAouhgdCK0X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}